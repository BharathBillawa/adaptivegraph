{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AdaptiveGraph Interactive Demo\n",
                "\n",
                "This notebook demonstrates how to use `adaptivegraph` with `langgraph` to create a self-optimizing workflow.\n",
                "\n",
                "We will build a simple routing agent that learns to send \"VIP\" users to a premium model and \"Guest\" users to a fast model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "78ee72fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install local package in editable mode with dev dependencies\n",
                "# This installs 'adaptivegraph' along with 'matplotlib' and other dev tools defined in pyproject.toml\n",
                "# NOTE: We use '..' because this notebook is inside the 'notebooks/' directory\n",
                "%pip install -e \"..[all]\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "2a65980f",
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import Literal, TypedDict\n",
                "from langgraph.graph import StateGraph, END\n",
                "from adaptivegraph import LearnableEdge\n",
                "\n",
                "# Define our state\n",
                "class AgentState(TypedDict):\n",
                "    user_type: str\n",
                "    query: str\n",
                "    path_taken: str\n",
                "    outcome: float"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c39cd91b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Nodes\n",
                "\n",
                "def start_node(state: AgentState):\n",
                "    print(f\"Processing request for {state['user_type']}...\")\n",
                "    return state\n",
                "\n",
                "def premium_model(state: AgentState):\n",
                "    return {\"path_taken\": \"premium\", \"outcome\": 1.0 if state[\"user_type\"] == \"vip\" else 0.0}\n",
                "\n",
                "def fast_model(state: AgentState):\n",
                "    return {\"path_taken\": \"fast\", \"outcome\": 1.0 if state[\"user_type\"] == \"guest\" else 0.0}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "aeda9ec8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the Learnable Edge\n",
                "\n",
                "router = LearnableEdge(\n",
                "    options=[\"premium\", \"fast\"],\n",
                "    policy=\"linucb\",\n",
                "    feature_dim=16,\n",
                "    exploration_alpha=0.5,\n",
                "    value_key=\"user_type\" # Extract this key from state automatically\n",
                ")\n",
                "# No wrapper needed anymore!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "a0ab9f96",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the Graph\n",
                "workflow = StateGraph(AgentState)\n",
                "\n",
                "workflow.add_node(\"start\", start_node)\n",
                "workflow.add_node(\"premium\", premium_model)\n",
                "workflow.add_node(\"fast\", fast_model)\n",
                "\n",
                "workflow.set_entry_point(\"start\")\n",
                "\n",
                "# Add conditional edge directly!\n",
                "workflow.add_conditional_edges(\n",
                "    \"start\",\n",
                "    router,\n",
                "    {\n",
                "        \"premium\": \"premium\",\n",
                "        \"fast\": \"fast\"\n",
                "    }\n",
                ")\n",
                "\n",
                "workflow.add_edge(\"premium\", END)\n",
                "workflow.add_edge(\"fast\", END)\n",
                "\n",
                "app = workflow.compile()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "e2947807",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulation Loop\n",
                "history = []\n",
                "accuracies = []\n",
                "\n",
                "for i in range(100):\n",
                "    # Generate synthetic data\n",
                "    u_type = \"vip\" if random.random() < 0.5 else \"guest\"\n",
                "    initial_state = {\"user_type\": u_type, \"query\": \"hello\", \"path_taken\": \"\", \"outcome\": 0.0}\n",
                "    \n",
                "    # Run Graph\n",
                "    result = app.invoke(initial_state)\n",
                "    \n",
                "    # Feedback Loop\n",
                "    # In this toy example, the nodes themselves calculated the 'outcome' (reward)\n",
                "    reward = result[\"outcome\"]\n",
                "    \n",
                "    # CRITICAL: Teach the router!\n",
                "    router.record_feedback(result, reward=reward)\n",
                "    \n",
                "    history.append(reward)\n",
                "    avg_acc = sum(history[-20:]) / len(history[-20:])\n",
                "    accuracies.append(avg_acc)\n",
                "    \n",
                "    if i % 10 == 0:\n",
                "        print(f\"Step {i}: Type={u_type}, Path={result['path_taken']}, Reward={reward}\")\n",
                "\n",
                "print(f\"Final Accuracy (last 20): {accuracies[-1]:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "1110ab80",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Learning Curve\n",
                "plt.plot(accuracies)\n",
                "plt.title(\"Routing Accuracy over Time\")\n",
                "plt.xlabel(\"Iterations\")\n",
                "plt.ylabel(\"Moving Average Accuracy\")\n",
                "plt.ylim(0, 1.1)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f42ccc54",
            "metadata": {},
            "source": [
                "## Advanced: Semantic Routing (Batteries Included)\n",
                "\n",
                "In this section, we will use `SentenceTransformer` to route requests based on their **semantic meaning** (text content) rather than a simple categorical tag.\n",
                "\n",
                "We will build a help-desk graph that routes queries to: `technical_support`, `billing`, or `general_chat`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "981c4bd0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Create the Semantic Router\n",
                "try:\n",
                "    # value_key=\"query\" tells the edge to look at state[\"query\"] for embedding\n",
                "    semantic_edge = LearnableEdge.create(\n",
                "        options=[\"technical_support\", \"billing\", \"general_chat\"],\n",
                "        embedding=\"sentence-transformers\",\n",
                "        memory=\"faiss\",\n",
                "        feature_dim=384, \n",
                "        exploration_alpha=0.2,\n",
                "        value_key=\"query\"\n",
                "    )\n",
                "    print(\"Semantic Edge created successfully!\")\n",
                "except ImportError:\n",
                "    print(\"Please install 'sentence-transformers' and 'faiss-cpu' to run this section.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "ffc00118",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Define Nodes and Graph\n",
                "\n",
                "class HelpState(TypedDict):\n",
                "    query: str\n",
                "    response: str\n",
                "\n",
                "def tech_node(state):\n",
                "    return {\"response\": \"Connecting you to an engineer...\"}\n",
                "\n",
                "def billing_node(state):\n",
                "    return {\"response\": \"Opening invoice portal...\"}\n",
                "\n",
                "def chat_node(state):\n",
                "    return {\"response\": \"I can help with general questions!\"}\n",
                "\n",
                "graph = StateGraph(HelpState)\n",
                "graph.add_node(\"start\", lambda x: x) # Pass through\n",
                "graph.add_node(\"technical_support\", tech_node)\n",
                "graph.add_node(\"billing\", billing_node)\n",
                "graph.add_node(\"general_chat\", chat_node)\n",
                "\n",
                "graph.set_entry_point(\"start\")\n",
                "\n",
                "# Use semantic_edge to route from start\n",
                "graph.add_conditional_edges(\n",
                "    \"start\",\n",
                "    semantic_edge,\n",
                "    {\n",
                "        \"technical_support\": \"technical_support\",\n",
                "        \"billing\": \"billing\",\n",
                "        \"general_chat\": \"general_chat\"\n",
                "    }\n",
                ")\n",
                "graph.add_edge(\"technical_support\", END)\n",
                "graph.add_edge(\"billing\", END)\n",
                "graph.add_edge(\"general_chat\", END)\n",
                "\n",
                "help_desk_app = graph.compile()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "209bc54d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Train the Semantic Router\n",
                "# We need to provide feedback so it learns which sentences correspond to which node.\n",
                "\n",
                "train_data = [\n",
                "    (\"My screen is black\", \"technical_support\"),\n",
                "    (\"Where is my invoice?\", \"billing\"),\n",
                "    (\"Hello there\", \"general_chat\"),\n",
                "    (\"Python script error\", \"technical_support\"),\n",
                "    (\"I want a refund\", \"billing\"),\n",
                "    (\"System crash\", \"technical_support\")\n",
                "]\n",
                "\n",
                "print(\"Training interactive graph...\")\n",
                "\n",
                "for i in range(50):\n",
                "    query, expected_node = random.choice(train_data)\n",
                "    \n",
                "    # Run the graph\n",
                "    initial = {\"query\": query, \"response\": \"\"}\n",
                "    # Note: In a real app, you would inspect the trace or return the node name to know where it went.\n",
                "    # Here, we use the edge directly to 'record_feedback' because we need to know what IT predicted.\n",
                "    # But let's verify via the output messages.\n",
                "    \n",
                "    # For training the bandit properly, we usually need the action it took.\n",
                "    # The 'semantic_edge' object stores the last action it performed internally.\n",
                "    \n",
                "    result = help_desk_app.invoke(initial)\n",
                "    resp = result[\"response\"]\n",
                "    \n",
                "    # Infer path taken from response (just for this demo)\n",
                "    path_taken = \"\"\n",
                "    if \"engineer\" in resp: path_taken = \"technical_support\"\n",
                "    elif \"invoice\" in resp: path_taken = \"billing\"\n",
                "    else: path_taken = \"general_chat\"\n",
                "\n",
                "    # Reward\n",
                "    reward = 1.0 if path_taken == expected_node else -0.5\n",
                "    \n",
                "    # Teach the edge\n",
                "    semantic_edge.record_feedback(result, reward)\n",
                "    \n",
                "    if i % 5 == 0:\n",
                "        print(f\"'{query}' -> {path_taken} (Reward: {reward})\")\n",
                "\n",
                "print(\"Training Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "42724968",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Test on NEW queries (Generalization)\n",
                "# The router should understand these concepts even if it hasn't seen the exact words.\n",
                "\n",
                "test_queries = [\n",
                "    \"My payment failed\",        # Should be Billing\n",
                "    \"Error 404 on the website\", # Should be Tech\n",
                "    \"Good morning team\"         # Should be Chat\n",
                "]\n",
                "\n",
                "print(\"\\n--- Generalization Test ---\")\n",
                "for q in test_queries:\n",
                "    res = help_desk_app.invoke({\"query\": q, \"response\": \"\"})\n",
                "    print(f\"Q: {q.ljust(30)} -> A: {res['response']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "adv_rew_1",
            "metadata": {},
            "source": [
                "## Advanced Reward Strategies\n",
                "\n",
                "This section specifically demonstrates the advanced reward mechanisms: **ID-based Async Feedback** and **ErrorScorer** utilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "adv_rew_2",
            "metadata": {},
            "outputs": [],
            "source": [
                "from adaptivegraph.rewards import ErrorScorer\n",
                "import uuid\n",
                "\n",
                "# 1. Setup ID-based Router\n",
                "# We reuse the semantic_edge but we demonstrate ID usage.\n",
                "\n",
                "print(\"--- ID-Based Async Feedback Demo ---\")\n",
                "\n",
                "# Scenario: User sends a query, we generate a trace_id.\n",
                "query = \"My laptop is broken\"\n",
                "trace_id = str(uuid.uuid4())\n",
                "\n",
                "# We put the ID in the state so the edge can track it.\n",
                "state = {\"query\": query, \"response\": \"\", \"event_id\": trace_id}\n",
                "\n",
                "result = help_desk_app.invoke(state)\n",
                "print(f\"[Processing {trace_id}] Query: '{query}' -> Response: '{result['response']}'\")\n",
                "\n",
                "# Now, simulate User Feedback happening 10 minutes later (Async)\n",
                "# We only need the ID and the score.\n",
                "print(\"User clicks 'Thumbs Down' (-1.0) ...\")\n",
                "\n",
                "semantic_edge.record_feedback(result={}, reward=-1.0, event_id=trace_id)\n",
                "print(\"Feedback recorded asynchronously!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "adv_rew_3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Using ErrorScorer Utility\n",
                "print(\"\\n--- ErrorScorer Utility Demo ---\")\n",
                "\n",
                "scorer = ErrorScorer(error_keys=[\"error\", \"exception\"], penalty=-2.0, success_reward=1.0)\n",
                "\n",
                "# Simulate a result with an error\n",
                "failed_state = {\"response\": \"Error\", \"exception\": \"Timeout\"}\n",
                "score = scorer.score(failed_state)\n",
                "print(f\"State with error -> Score: {score}\")\n",
                "\n",
                "# Simulate success\n",
                "good_state = {\"response\": \"Success\"}\n",
                "score = scorer.score(good_state)\n",
                "print(f\"State without error -> Score: {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "traj_rew_1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Trajectory / Delayed Rewards\n",
                "print(\"\\n--- Trajectory Reward Demo ---\")\n",
                "\n",
                "# Imagine a session where the user asks 3 questions.\n",
                "session_id = \"session_xyz_789\"\n",
                "\n",
                "queries = [\n",
                "    \"How do I pay?\",        # Should route to billing\n",
                "    \"Is the site down?\",    # Should route to tech\n",
                "    \"Thank you!\"            # Should route to chat\n",
                "]\n",
                "\n",
                "for q in queries:\n",
                "    # Pass 'trace_id' in state to link these together\n",
                "    st = {\"query\": q, \"trace_id\": session_id}\n",
                "    # We invoke the app (which calls the edge internally)\n",
                "    res = help_desk_app.invoke(st)\n",
                "    print(f\"Session Step: '{q}' -> {res.get('response', 'ok')}\")\n",
                "\n",
                "# At the end of the session, the user rates the Whole interaction as 5 stars.\n",
                "print(\"Session Complete. User rates 5/5 stars!\")\n",
                "\n",
                "# We reward ALL steps in this session at once.\n",
                "# decay=0.9 means later steps get slightly more credit, or use 1.0 for equal credit.\n",
                "semantic_edge.complete_trace(trace_id=session_id, final_reward=1.0, decay=0.9)\n",
                "print(\"Reward propagated to all 3 steps in the trajectory.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}