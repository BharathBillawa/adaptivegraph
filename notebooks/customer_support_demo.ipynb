{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AdaptiveGraph: Customer Support Agent Demo\n",
                "\n",
                "This interactive notebook demonstrates the **'Tiered Customer Support Agent'** use case.\n",
                "\n",
                "**Scenario:** You have 3 support channels with different costs and capabilities:\n",
                "1.  **QuickBot** (Free, Instant): Handles simple FAQs like \"reset password\". Fails on complex queries.\n",
                "2.  **RAG Agent** (Medium Cost): Uses docs to answer questions. Can sometimes timeout/crash.\n",
                "3.  **Human Expert** (Expensive): Solves everything perfectly.\n",
                "\n",
                "**Goal:** Build an agent that learns to route tickets to the cheapest channel that can successfully solve the problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if running in Colab/Fresh Env\n",
                "%pip install -e \"..[all]\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import random\n",
                "import uuid\n",
                "import time\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import TypedDict, Literal, Optional\n",
                "from langgraph.graph import StateGraph, END\n",
                "from adaptivegraph import LearnableEdge, ErrorScorer, LLMScorer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Define the Agent State"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SupportState(TypedDict):\n",
                "    ticket_id: str          # Trace ID / Session ID\n",
                "    user_tier: str          # \"Free\" or \"Premium\"\n",
                "    query: str              # User text\n",
                "    \n",
                "    # Internal Flow\n",
                "    route_decision: str     # Where did we go?\n",
                "    tool_output: str        # Tool result\n",
                "    error: Optional[str]    # Did tool crash?\n",
                "    \n",
                "    trace_id: str           # Required for Trajectory Rewards\n",
                "    event_id: str           # Required for Async User Feedback"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Define the Router (The Brain)\n",
                "\n",
                "We use `LearnableEdge` with `sentence-transformers` embedding. This allows the router to understand the *meaning* of the support ticket (\"My screen is black\" ~= \"Display failure\")."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "router = LearnableEdge.create(\n",
                "    options=[\"quick_bot\", \"rag_agent\", \"human_expert\"],\n",
                "    embedding=\"sentence-transformers\",\n",
                "    memory=\"memory\", # Transient memory for this demo\n",
                "    feature_dim=384,\n",
                "    value_key=\"query\" # Route based on the 'query' text\n",
                ")\n",
                "print(\"Router Initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Define the Nodes (The Workers)\n",
                "\n",
                "These simulate our support channels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def triage_node(state: SupportState):\n",
                "    # Entry point\n",
                "    return state\n",
                "\n",
                "def quick_bot_node(state: SupportState):\n",
                "    # Only handles simple keywords\n",
                "    if \"reset\" in state[\"query\"].lower() or \"password\" in state[\"query\"].lower():\n",
                "        return {\"tool_output\": \"Here is the link to reset password.\", \"route_decision\": \"quick_bot\"}\n",
                "    else:\n",
                "        # Failure case\n",
                "        return {\"tool_output\": \"Unknown command.\", \"error\": \"BotConfused\", \"route_decision\": \"quick_bot\"}\n",
                "\n",
                "def rag_agent_node(state: SupportState):\n",
                "    # Simulates RAG. Has a chance of crashing (Timeout)\n",
                "    if \"error\" in state[\"query\"].lower() and random.random() < 0.3:\n",
                "        return {\"tool_output\": \"\", \"error\": \"VectorDBTimeout\", \"route_decision\": \"rag_agent\"}\n",
                "    return {\"tool_output\": f\"Docs result for '{state['query']}'\", \"route_decision\": \"rag_agent\"}\n",
                "\n",
                "def human_expert_node(state: SupportState):\n",
                "    # Always works\n",
                "    return {\"tool_output\": \"Human: I fixed it for you.\", \"route_decision\": \"human_expert\"}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Build the Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "workflow = StateGraph(SupportState)\n",
                "\n",
                "workflow.add_node(\"triage\", triage_node)\n",
                "workflow.add_node(\"quick_bot\", quick_bot_node)\n",
                "workflow.add_node(\"rag_agent\", rag_agent_node)\n",
                "workflow.add_node(\"human_expert\", human_expert_node)\n",
                "\n",
                "workflow.set_entry_point(\"triage\")\n",
                "\n",
                "# The Routing Magic Happens Here\n",
                "workflow.add_conditional_edges(\n",
                "    \"triage\",\n",
                "    router,\n",
                "    {\n",
                "        \"quick_bot\": \"quick_bot\",\n",
                "        \"rag_agent\": \"rag_agent\",\n",
                "        \"human_expert\": \"human_expert\"\n",
                "    }\n",
                ")\n",
                "\n",
                "workflow.add_edge(\"quick_bot\", END)\n",
                "workflow.add_edge(\"rag_agent\", END)\n",
                "workflow.add_edge(\"human_expert\", END)\n",
                "\n",
                "app = workflow.compile()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Demo: Async User Feedback (ID-Based)\n",
                "\n",
                "This demonstrates how a user can provide feedback **hours later** by simply referencing the ticket ID."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== Async User Feedback Demo ===\")\n",
                "\n",
                "# Step 1: User submits a ticket\n",
                "ticket_id = \"TICKET-12345\"\n",
                "user_query = \"I need help with billing\"\n",
                "\n",
                "state = {\n",
                "    \"ticket_id\": ticket_id,\n",
                "    \"event_id\": ticket_id,  # The router will track this decision by this ID\n",
                "    \"trace_id\": ticket_id,\n",
                "    \"user_tier\": \"Premium\",\n",
                "    \"query\": user_query,\n",
                "    \"route_decision\": \"\",\n",
                "    \"tool_output\": \"\",\n",
                "    \"error\": None\n",
                "}\n",
                "\n",
                "# Step 2: Agent processes the ticket\n",
                "result = app.invoke(state)\n",
                "print(f\"Ticket {ticket_id} processed.\")\n",
                "print(f\"  Query: '{user_query}'\")\n",
                "print(f\"  Routed to: {result['route_decision']}\")\n",
                "print(f\"  Response: {result['tool_output']}\")\n",
                "\n",
                "# Step 3: Simulate time passing (2 hours later...)\n",
                "print(\"\\n[2 hours later...]\")\n",
                "\n",
                "# Step 4: User clicks 'Thumbs Up' in an email\n",
                "user_rating = 1.0  # Happy!\n",
                "print(f\"User rated ticket {ticket_id}: {user_rating} (Thumbs Up!)\")\n",
                "\n",
                "# Step 5: Backend receives the feedback and updates the router\n",
                "router.record_feedback(result={}, reward=user_rating, event_id=ticket_id)\n",
                "print(f\"Router updated based on user feedback for ticket {ticket_id}.\")\n",
                "print(\"\\nThis decision is now stored in memory and will influence future routing!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Interactive Simulation\n",
                "\n",
                "Now let's run a full simulation with trajectory rewards."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "error_scorer = ErrorScorer(penalty=-1.0, success_reward=0.1)\n",
                "\n",
                "# Store history for plotting\n",
                "global_reward_history = []\n",
                "\n",
                "def run_ticket_simulation(num_tickets=50):\n",
                "    queries = [\n",
                "        (\"How do I reset my password?\", \"quick_bot\"),     # Simple -> Bot\n",
                "        (\"Critical server error 500\", \"human_expert\"),    # Complex -> Human\n",
                "        (\"Where are the docs?\", \"rag_agent\"),             # Medium -> RAG\n",
                "        (\"I want a refund!\", \"human_expert\"),             # Money/Angry -> Human\n",
                "    ]\n",
                "    \n",
                "    async_feedback_queue = []\n",
                "    \n",
                "    print(f\"--- Processing {num_tickets} Tickets ---\")\n",
                "    \n",
                "    for i in range(num_tickets):\n",
                "        q_text, ideal_route = random.choice(queries)\n",
                "        t_id = str(uuid.uuid4())[:6]\n",
                "        \n",
                "        state = {\n",
                "            \"ticket_id\": t_id,\n",
                "            \"event_id\": t_id,\n",
                "            \"user_tier\": \"Free\",\n",
                "            \"query\": q_text,\n",
                "            \"trace_id\": t_id, # CRITICAL for Trajectory Rewards\n",
                "            \"route_decision\": \"\", \"tool_output\": \"\", \"error\": None\n",
                "        }\n",
                "        \n",
                "        # RUN AGENT\n",
                "        result = app.invoke(state)\n",
                "        path = result['route_decision']\n",
                "        \n",
                "        # 1. CHECK FOR CRASHES (Immediate)\n",
                "        crash_score = error_scorer.score(result)\n",
                "        if crash_score < 0:\n",
                "            print(f\"[{t_id}] CRASH! Tool '{path}' failed ({result['error']}). Penalty Applied.\")\n",
                "            router.complete_trace(t_id, final_reward=-1.0)\n",
                "            global_reward_history.append(-1.0)\n",
                "            continue\n",
                "            \n",
                "        # 2. QUEUE FOR USER FEEDBACK (Delayed)\n",
                "        # Simulate user happiness\n",
                "        satisfaction = 0.1\n",
                "        if path == ideal_route: satisfaction = 1.0\n",
                "        elif path == \"human_expert\": satisfaction = 0.9 # Everyone likes humans\n",
                "        elif path == \"quick_bot\" and ideal_route != \"quick_bot\": satisfaction = 0.0 # Hated it\n",
                "        \n",
                "        async_feedback_queue.append({\"id\": t_id, \"score\": satisfaction, \"query\": q_text, \"path\": path})\n",
                "\n",
                "        # Process Feedback every 5 tickets\n",
                "        if len(async_feedback_queue) >= 5:\n",
                "            for item in async_feedback_queue:\n",
                "                # RETROSPECTIVE REWARD\n",
                "                router.complete_trace(item[\"id\"], final_reward=item[\"score\"])\n",
                "                global_reward_history.append(item[\"score\"])\n",
                "            async_feedback_queue = []\n",
                "    print(\"Done!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run it!\n",
                "run_ticket_simulation(50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Visualize Improvement\n",
                "See how the reward (Satisfaction) increases over time as the router learns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def moving_average(a, n=5):\n",
                "    ret = []\n",
                "    for i in range(len(a)):\n",
                "        subset = a[max(0, i-n):i+1]\n",
                "        ret.append(sum(subset)/len(subset))\n",
                "    return ret\n",
                "\n",
                "smoothed = moving_average(global_reward_history, 10)\n",
                "plt.plot(smoothed)\n",
                "plt.xlabel(\"Tickets Processed\")\n",
                "plt.ylabel(\"Avg. User Satisfaction\")\n",
                "plt.title(\"Agent Learning Curve\")\n",
                "plt.ylim(-0.2, 1.1)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Bonus: LLM-as-a-Judge\n",
                "Instead of waiting for a human, we can ask an LLM to rate the answer immediately."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mock LLM for demo purposes (you would use OpenAI/Anthropic in real life)\n",
                "class MockChain:\n",
                "    def invoke(self, prompt: str) -> str:\n",
                "        if \"bad\" in prompt.lower() or \"error\" in prompt.lower():\n",
                "            return \"Score: 2/10\"\n",
                "        return \"Score: 9/10\"\n",
                "\n",
                "mock_llm = MockChain()\n",
                "\n",
                "llm_scorer = LLMScorer(mock_llm, prompt_template=\"Rate this response: {response} for query: {query}\")\n",
                "\n",
                "# Demo:\n",
                "score = llm_scorer.score(query=\"Help me\", response=\"Here is a helpful answer.\")\n",
                "print(f\"LLM Scorer gave: {score}\")\n",
                "\n",
                "score_bad = llm_scorer.score(query=\"Help me\", response=\"System Error 500\")\n",
                "print(f\"LLM Scorer gave (bad): {score_bad}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conclusion\n",
                "\n",
                "We have demonstrated:\n",
                "1. **Async User Feedback**: Users can rate tickets hours later using just the ticket ID.\n",
                "2. **Semantic Routing**: Learning from text.\n",
                "3. **Safety**: Catching tool crashes with `ErrorScorer`.\n",
                "4. **Long-term Optimization**: Using Trajectory Rewards to optimize for the final outcome.\n",
                "5. **Visualization**: Seeing the policy improve over time.\n",
                "6. **LLM Judge**: Automatic quality scoring."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}